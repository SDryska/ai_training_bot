#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö EMCO Assessment Bot
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –ë–î, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–∞–±–ª–∏—Ü –∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
"""

import asyncio
import asyncpg
import json
import os
from datetime import datetime
from typing import Dict, Any, List, Optional
from pydantic_settings import BaseSettings
from pydantic import Field
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()


class Settings(BaseSettings):
    DATABASE_URL: str = Field(..., description="postgresql+asyncpg://...")
    
    model_config = {
        'env_file': '.env',
        'case_sensitive': False,
        'extra': 'ignore'  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –∏–∑ .env
    }


def normalize_db_url(database_url: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL –¥–ª—è asyncpg"""
    if database_url.startswith("postgresql+asyncpg://"):
        return database_url.replace("postgresql+asyncpg://", "postgresql://")
    return database_url


def format_bytes(size_bytes: int) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä –≤ –±–∞–π—Ç–∞—Ö –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.2f} {size_names[i]}"


def format_datetime(dt) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç datetime –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    if dt is None:
        return "N/A"
    if hasattr(dt, 'strftime'):
        return dt.strftime("%Y-%m-%d %H:%M:%S UTC")
    return str(dt)


class DatabaseAnalyzer:
    def __init__(self):
        self.settings = Settings()
        self.conn: Optional[asyncpg.Connection] = None
    
    async def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        url = normalize_db_url(self.settings.DATABASE_URL)
        print(f"üîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
        self.conn = await asyncpg.connect(url, timeout=30)
        print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    
    async def disconnect(self):
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        if self.conn:
            await self.conn.close()
            print("üîå –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ")
    
    async def get_database_size(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–º–µ—Ä–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        print("\nüìä –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        
        # –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—É—â–µ–π –ë–î
        db_size_query = """
        SELECT pg_size_pretty(pg_database_size(current_database())) as size,
               pg_database_size(current_database()) as size_bytes
        """
        
        db_size = await self.conn.fetchrow(db_size_query)
        
        # –†–∞–∑–º–µ—Ä—ã —Ç–∞–±–ª–∏—Ü
        tables_size_query = """
        SELECT 
            schemaname,
            tablename,
            pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
            pg_total_relation_size(schemaname||'.'||tablename) as size_bytes,
            pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size,
            pg_relation_size(schemaname||'.'||tablename) as table_size_bytes,
            pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) as indexes_size
        FROM pg_tables 
        WHERE schemaname = 'public'
        ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
        """
        
        tables_info = await self.conn.fetch(tables_size_query)
        
        return {
            'database_size': db_size['size'],
            'database_size_bytes': db_size['size_bytes'],
            'tables': [dict(row) for row in tables_info]
        }
    
    async def get_table_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º"""
        print("üìà –°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º...")
        
        stats = {}
        
        # –°–ø–∏—Å–æ–∫ –Ω–∞—à–∏—Ö –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
        tables = ['authorized_users', 'bot_ratings', 'case_stats', 'rating_invites']
        
        for table in tables:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
            exists_query = """
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = $1
            )
            """
            
            exists = await self.conn.fetchval(exists_query, table)
            
            if not exists:
                stats[table] = {'exists': False}
                continue
            
            # –ü–æ–¥—Å—á–µ—Ç –∑–∞–ø–∏—Å–µ–π
            count_query = f"SELECT COUNT(*) FROM {table}"
            count = await self.conn.fetchval(count_query)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–ª–æ–Ω–∫–∞—Ö
            columns_query = """
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns
            WHERE table_schema = 'public' AND table_name = $1
            ORDER BY ordinal_position
            """
            
            columns = await self.conn.fetch(columns_query, table)
            
            stats[table] = {
                'exists': True,
                'row_count': count,
                'columns': [dict(col) for col in columns]
            }
        
        return stats
    
    async def export_all_data(self) -> Dict[str, Any]:
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã"""
        print("üì§ –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        data = {}
        
        # authorized_users
        try:
            users_query = """
            SELECT user_id, role, created_at
            FROM authorized_users
            ORDER BY created_at DESC
            """
            users = await self.conn.fetch(users_query)
            data['authorized_users'] = [
                {
                    'user_id': row['user_id'],
                    'role': row['role'],
                    'created_at': format_datetime(row['created_at'])
                }
                for row in users
            ]
        except Exception as e:
            data['authorized_users'] = {'error': str(e)}
        
        # bot_ratings
        try:
            ratings_query = """
            SELECT user_id, question, rating, updated_at
            FROM bot_ratings
            ORDER BY updated_at DESC
            """
            ratings = await self.conn.fetch(ratings_query)
            data['bot_ratings'] = [
                {
                    'user_id': row['user_id'],
                    'question': row['question'],
                    'rating': row['rating'],
                    'updated_at': format_datetime(row['updated_at'])
                }
                for row in ratings
            ]
        except Exception as e:
            data['bot_ratings'] = {'error': str(e)}
        
        # case_stats
        try:
            stats_query = """
            SELECT user_id, case_id, stat, cnt, updated_at
            FROM case_stats
            ORDER BY updated_at DESC
            """
            stats = await self.conn.fetch(stats_query)
            data['case_stats'] = [
                {
                    'user_id': row['user_id'],
                    'case_id': row['case_id'],
                    'stat': row['stat'],
                    'count': row['cnt'],
                    'updated_at': format_datetime(row['updated_at'])
                }
                for row in stats
            ]
        except Exception as e:
            data['case_stats'] = {'error': str(e)}
        
        # rating_invites
        try:
            invites_query = """
            SELECT user_id, sent_at
            FROM rating_invites
            ORDER BY sent_at DESC
            """
            invites = await self.conn.fetch(invites_query)
            data['rating_invites'] = [
                {
                    'user_id': row['user_id'],
                    'sent_at': format_datetime(row['sent_at'])
                }
                for row in invites
            ]
        except Exception as e:
            data['rating_invites'] = {'error': str(e)}
        
        return data
    
    async def get_aggregated_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        print("üî¢ –ü–æ–¥—Å—á–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
        
        stats = {}
        
        try:
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ —Ä–æ–ª—è–º
            users_by_role_query = """
            SELECT role, COUNT(*) as count
            FROM authorized_users
            GROUP BY role
            ORDER BY count DESC
            """
            users_by_role = await self.conn.fetch(users_by_role_query)
            stats['users_by_role'] = {row['role']: row['count'] for row in users_by_role}
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
            ratings_stats_query = """
            SELECT 
                question,
                COUNT(*) as total_responses,
                AVG(rating::float) as avg_rating,
                MIN(rating) as min_rating,
                MAX(rating) as max_rating
            FROM bot_ratings
            GROUP BY question
            ORDER BY question
            """
            ratings_stats = await self.conn.fetch(ratings_stats_query)
            stats['ratings_by_question'] = [
                {
                    'question': row['question'],
                    'total_responses': row['total_responses'],
                    'average_rating': round(float(row['avg_rating']), 2) if row['avg_rating'] else 0,
                    'min_rating': row['min_rating'],
                    'max_rating': row['max_rating']
                }
                for row in ratings_stats
            ]
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–µ–π—Å–∞–º
            case_stats_query = """
            SELECT 
                case_id,
                stat,
                COUNT(*) as user_count,
                SUM(cnt) as total_count
            FROM case_stats
            GROUP BY case_id, stat
            ORDER BY case_id, stat
            """
            case_stats = await self.conn.fetch(case_stats_query)
            stats['case_statistics'] = [
                {
                    'case_id': row['case_id'],
                    'stat_type': row['stat'],
                    'unique_users': row['user_count'],
                    'total_occurrences': row['total_count']
                }
                for row in case_stats
            ]
            
            # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            user_activity_query = """
            SELECT 
                COUNT(DISTINCT user_id) as total_active_users,
                COUNT(DISTINCT CASE WHEN rating IS NOT NULL THEN user_id END) as users_with_ratings,
                COUNT(DISTINCT CASE WHEN cnt > 0 THEN user_id END) as users_with_case_activity
            FROM authorized_users au
            LEFT JOIN bot_ratings br ON au.user_id = br.user_id
            LEFT JOIN case_stats cs ON au.user_id = cs.user_id
            """
            activity = await self.conn.fetchrow(user_activity_query)
            stats['user_activity'] = dict(activity) if activity else {}
            
        except Exception as e:
            stats['error'] = str(e)
        
        return stats
    
    def print_size_report(self, size_info: Dict[str, Any]):
        """–í—ã–≤–æ–¥–∏—Ç –æ—Ç—á–µ—Ç –æ —Ä–∞–∑–º–µ—Ä–µ –ë–î"""
        print("\n" + "="*60)
        print("üìä –û–¢–ß–ï–¢ –û –†–ê–ó–ú–ï–†–ï –ë–ê–ó–´ –î–ê–ù–ù–´–•")
        print("="*60)
        
        print(f"\nüóÑÔ∏è  –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {size_info['database_size']}")
        print(f"    ({format_bytes(size_info['database_size_bytes'])})")
        
        print(f"\nüìã –†–∞–∑–º–µ—Ä—ã —Ç–∞–±–ª–∏—Ü:")
        for table in size_info['tables']:
            print(f"  ‚Ä¢ {table['tablename']}: {table['size']}")
            print(f"    - –î–∞–Ω–Ω—ã–µ: {table['table_size']}")
            print(f"    - –ò–Ω–¥–µ–∫—Å—ã: {table['indexes_size']}")
    
    def print_statistics_report(self, stats: Dict[str, Any]):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç"""
        print("\n" + "="*60)
        print("üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–ê–ë–õ–ò–¶")
        print("="*60)
        
        for table_name, table_stats in stats.items():
            print(f"\nüìä –¢–∞–±–ª–∏—Ü–∞: {table_name}")
            
            if not table_stats.get('exists', True):
                print("  ‚ùå –¢–∞–±–ª–∏—Ü–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                continue
            
            print(f"  üìù –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {table_stats['row_count']:,}")
            print(f"  üèóÔ∏è  –°—Ç—Ä—É–∫—Ç—É—Ä–∞:")
            
            for col in table_stats['columns']:
                nullable = "NULL" if col['is_nullable'] == 'YES' else "NOT NULL"
                default = f" DEFAULT {col['column_default']}" if col['column_default'] else ""
                print(f"    - {col['column_name']}: {col['data_type']} {nullable}{default}")
    
    def print_aggregated_report(self, agg_stats: Dict[str, Any]):
        """–í—ã–≤–æ–¥–∏—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç"""
        print("\n" + "="*60)
        print("üî¢ –ê–ì–†–ï–ì–ò–†–û–í–ê–ù–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("="*60)
        
        if 'users_by_role' in agg_stats:
            print(f"\nüë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –ø–æ —Ä–æ–ª—è–º:")
            for role, count in agg_stats['users_by_role'].items():
                print(f"  ‚Ä¢ {role}: {count:,} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
        
        if 'ratings_by_question' in agg_stats:
            print(f"\n‚≠ê –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤:")
            for rating in agg_stats['ratings_by_question']:
                print(f"  ‚Ä¢ {rating['question']}:")
                print(f"    - –û—Ç–≤–µ—Ç–æ–≤: {rating['total_responses']:,}")
                print(f"    - –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥: {rating['average_rating']}/10")
                print(f"    - –î–∏–∞–ø–∞–∑–æ–Ω: {rating['min_rating']}-{rating['max_rating']}")
        
        if 'case_statistics' in agg_stats:
            print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–µ–π—Å–∞–º:")
            current_case = None
            for case_stat in agg_stats['case_statistics']:
                if case_stat['case_id'] != current_case:
                    current_case = case_stat['case_id']
                    print(f"  ‚Ä¢ –ö–µ–π—Å: {current_case}")
                
                print(f"    - {case_stat['stat_type']}: {case_stat['unique_users']} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, {case_stat['total_occurrences']} —Ä–∞–∑")
        
        if 'user_activity' in agg_stats:
            activity = agg_stats['user_activity']
            print(f"\nüéØ –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π:")
            print(f"  ‚Ä¢ –í—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {activity.get('total_active_users', 0):,}")
            print(f"  ‚Ä¢ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ä–µ–π—Ç–∏–Ω–≥–∞–º–∏: {activity.get('users_with_ratings', 0):,}")
            print(f"  ‚Ä¢ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é –ø–æ –∫–µ–π—Å–∞–º: {activity.get('users_with_case_activity', 0):,}")
    
    def save_data_to_files(self, data: Dict[str, Any], size_info: Dict[str, Any], 
                          stats: Dict[str, Any], agg_stats: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª—ã"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –ü–æ–ª–Ω—ã–π –¥–∞–º–ø –¥–∞–Ω–Ω—ã—Ö –≤ JSON
        full_data = {
            'export_timestamp': datetime.now().isoformat(),
            'database_size': size_info,
            'table_statistics': stats,
            'aggregated_statistics': agg_stats,
            'raw_data': data
        }
        
        json_filename = f"db_export_{timestamp}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(full_data, f, ensure_ascii=False, indent=2, default=str)
        
        # –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç
        report_filename = f"db_report_{timestamp}.txt"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write("EMCO Assessment Bot - –ê–Ω–∞–ª–∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n")
            f.write(f"–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*60 + "\n\n")
            
            # –†–∞–∑–º–µ—Ä –ë–î
            f.write(f"–†–ê–ó–ú–ï–† –ë–ê–ó–´ –î–ê–ù–ù–´–•\n")
            f.write(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {size_info['database_size']}\n\n")
            
            f.write("–†–∞–∑–º–µ—Ä—ã —Ç–∞–±–ª–∏—Ü:\n")
            for table in size_info['tables']:
                f.write(f"  {table['tablename']}: {table['size']}\n")
            f.write("\n")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–ê–ë–õ–ò–¶\n")
            for table_name, table_stats in stats.items():
                if table_stats.get('exists', True):
                    f.write(f"{table_name}: {table_stats['row_count']:,} –∑–∞–ø–∏—Å–µ–π\n")
            f.write("\n")
            
            # –î–∞–Ω–Ω—ã–µ
            f.write("–°–û–î–ï–†–ñ–ò–ú–û–ï –¢–ê–ë–õ–ò–¶\n")
            f.write("-" * 40 + "\n\n")
            
            for table_name, table_data in data.items():
                f.write(f"{table_name.upper()}:\n")
                if isinstance(table_data, list):
                    for i, record in enumerate(table_data, 1):
                        f.write(f"  –ó–∞–ø–∏—Å—å {i}:\n")
                        for key, value in record.items():
                            f.write(f"    {key}: {value}\n")
                        f.write("\n")
                else:
                    f.write(f"  –û—à–∏–±–∫–∞: {table_data}\n")
                f.write("-" * 40 + "\n")
        
        print(f"\nüíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
        print(f"  üìÑ JSON –¥–∞–º–ø: {json_filename}")
        print(f"  üìÑ –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç: {report_filename}")
    
    async def run_full_analysis(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            await self.connect()
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            size_info = await self.get_database_size()
            stats = await self.get_table_statistics()
            agg_stats = await self.get_aggregated_statistics()
            data = await self.export_all_data()
            
            # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç—ã
            self.print_size_report(size_info)
            self.print_statistics_report(stats)
            self.print_aggregated_report(agg_stats)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª—ã
            self.save_data_to_files(data, size_info, stats, agg_stats)
            
            print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
            raise
        finally:
            await self.disconnect()


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ EMCO Assessment Bot - –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    print("="*60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if not os.getenv('DATABASE_URL'):
        print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è DATABASE_URL")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª .env —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç DATABASE_URL")
        return
    
    analyzer = DatabaseAnalyzer()
    await analyzer.run_full_analysis()


if __name__ == "__main__":
    asyncio.run(main())
